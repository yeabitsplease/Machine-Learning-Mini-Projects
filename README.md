# MACHINE LEARNING MINI PROJECT SERIES

# Behind the lines
> Maintainer - [Govind Saxena](https://github.com/yeabitsplease)

## Table of Contents
- [Machine Learning Workflow](#machine-learning-workflow)



## Machine Learning Workflow
* Gathering data
* Data pre-processing
* Researching the model that will be best for the type of data
* Training and testing the model

## Workflow

### Gathering Data
 * The data set can be collected from various sources such as a file, database, sensor and many other such sources which are present on the internet. Kaggle and UCI Machine learning Repository are the repositories that are used the most for making Machine learning models. Kaggle is one of the most visited websites that is used for practicing machine learning algorithms, they also host competitions in which people can participate and get to test their knowledge of machine learning.
 
### Data Preprocessing
 * In machine learning, there is an *80/20* rule. Every data scientist should spend 80% time for data pre-processing and 20% time to actually perform the analysis.
 
 * `What is Data Preprocessing and why do we need it?`
   * Data pre-processing is a process of cleaning the raw data i.e. the data is collected in the real world and is converted to a clean data set.
   * In other words,   whenever the data is gathered from different sources it is collected in a raw format and this data isnâ€™t feasible for the analysis.
     Therefore, certain steps are executed to convert the data into a small clean data set, this part of the process is called as data pre-processing.
 * `Need of Preprocessing`
    * As we know that data pre-processing is a process of cleaning the raw data into clean data, so that can be used to train the model. So, we definitely need data  pre-processing to achieve good results from the applied model in machine learning and deep learning projects.
   

